{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/python\n",
    "# -*- coding: UTF-8 -*-\n",
    "# word2vec\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"w2v_japan\" # target file\n",
    "file = \"seg_japan\" # seg file\n",
    "word_list_file = \"att_japan\"\n",
    "\n",
    "MAX_VOCAB_SIZE = \"all\"\n",
    "\n",
    "EMBED_SIZE = 256 # word vector size\n",
    "WINDOW = 5 # context window\n",
    "NEGATIVE = 10 # number of negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15003522.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_all = []\n",
    "with open(\"source/{}.txt\".format(file), 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        sentences_all.append(line.strip().split(\" \"))\n",
    "\n",
    "w2v_model = models.Word2Vec(sentences=sentences_all, size=EMBED_SIZE, \\\n",
    "                            sg=1, window=WINDOW, min_count=1, \\\n",
    "                            compute_loss=True, hs=0, \\\n",
    "                           negative=NEGATIVE)\n",
    "w2v_model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for word list\n",
    "import pickle\n",
    "with open (\"result/{}\".format(word_list_file), 'rb') as f:\n",
    "    data = pd.DataFrame(pickle.load(f))\n",
    "word_list = list(data[\"words\"])\n",
    "word_list.remove(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>，</td>\n",
       "      <td>[0.048403893, -0.20811214, -0.24412213, 0.1115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>的</td>\n",
       "      <td>[-0.04322757, -0.16477053, -0.12281142, -0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>。</td>\n",
       "      <td>[0.153654, -0.28800693, -0.091031045, 0.051172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>是</td>\n",
       "      <td>[0.17306003, -0.4055268, -0.3539127, 0.1159778...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>了</td>\n",
       "      <td>[-0.1644919, -0.07302851, -0.45514983, -0.0158...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words                                            vectors\n",
       "0     ，  [0.048403893, -0.20811214, -0.24412213, 0.1115...\n",
       "1     的  [-0.04322757, -0.16477053, -0.12281142, -0.062...\n",
       "2     。  [0.153654, -0.28800693, -0.091031045, 0.051172...\n",
       "3     是  [0.17306003, -0.4055268, -0.3539127, 0.1159778...\n",
       "4     了  [-0.1644919, -0.07302851, -0.45514983, -0.0158..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vectors = []\n",
    "for word in word_list:\n",
    "    new_vectors.append(w2v_model.wv[word])\n",
    "\n",
    "pddata = pd.DataFrame({\"words\": word_list, \"vectors\": new_vectors})\n",
    "pddata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_VOCAB_SIZE = len(word_list)\n",
    "\n",
    "# with open(\"result/ca_evaluation/test.txt\", 'w', encoding='utf-8') as f:\n",
    "#     f.write(\"{} {}\\n\".format(MAX_VOCAB_SIZE, EMBED_SIZE))\n",
    "#     for word, vector in zip(word_list, new_vectors):\n",
    "#         f.write(\"{} {}\\n\".format(word, \" \".join('{}'.format(i) for i in vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"result/{}\".format(name), 'wb') as f:\n",
    "    pickle.dump(pddata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
